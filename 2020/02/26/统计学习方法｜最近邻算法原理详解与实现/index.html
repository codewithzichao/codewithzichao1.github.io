<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"codewithzichao.github.io","root":"/","scheme":"Muse","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="KNN算法是一种较为简单的分类算法（也可用于回归问题），其可以实现多分类问题。本篇博客将详细地讲解KNN算法，并采用python与scikit-learn库两种方式，对KNN算法进行实现。">
<meta property="og:type" content="article">
<meta property="og:title" content="统计学习方法|K近邻算法原理详解与实现">
<meta property="og:url" content="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="codewithzichao">
<meta property="og:description" content="KNN算法是一种较为简单的分类算法（也可用于回归问题），其可以实现多分类问题。本篇博客将详细地讲解KNN算法，并采用python与scikit-learn库两种方式，对KNN算法进行实现。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/1.jpg">
<meta property="article:published_time" content="2020-02-26T09:33:33.000Z">
<meta property="article:modified_time" content="2020-02-27T14:25:19.811Z">
<meta property="article:author" content="zichao">
<meta property="article:tag" content="python">
<meta property="article:tag" content="统计学习方法">
<meta property="article:tag" content="scikit-learn">
<meta property="article:tag" content="KNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg">


<link rel="canonical" href="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>统计学习方法|K近邻算法原理详解与实现 | codewithzichao</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">codewithzichao</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Confident，Modest，Patient</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#knn算法介绍"><span class="nav-number">1.</span> <span class="nav-text">KNN算法介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k值的选择"><span class="nav-number">2.</span> <span class="nav-text">K值的选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#距离的计算"><span class="nav-number">3.</span> <span class="nav-text">距离的计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类决策规则"><span class="nav-number">4.</span> <span class="nav-text">分类决策规则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kd-tree"><span class="nav-number">5.</span> <span class="nav-text">kd tree</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#knn算法的实现"><span class="nav-number">6.</span> <span class="nav-text">KNN算法的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python实现"><span class="nav-number">6.1.</span> <span class="nav-text">python实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scikit-learn实现"><span class="nav-number">6.2.</span> <span class="nav-text">scikit-learn实现</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zichao</p>
  <div class="site-description" itemprop="description">Just learning</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">80</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">117</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://codewithzichao.github.io/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zichao">
      <meta itemprop="description" content="Just learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codewithzichao">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          统计学习方法|K近邻算法原理详解与实现
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-26 17:33:33" itemprop="dateCreated datePublished" datetime="2020-02-26T17:33:33+08:00">2020-02-26</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-02-27 22:25:19" itemprop="dateModified" datetime="2020-02-27T22:25:19+08:00">2020-02-27</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>KNN算法是一种较为简单的分类算法（也可用于回归问题），其可以实现多分类问题。本篇博客将详细地讲解KNN算法，并采用python与scikit-learn库两种方式，对KNN算法进行实现。</p>
<a id="more"></a>
<h2 id="knn算法介绍">KNN算法介绍</h2>
<p>KNN算法是比较简单的。它的整个应用过程如下：</p>
<p>输入：给定训练数据集<span class="math inline">\(X=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)</span>，其中，<span class="math inline">\(x_i=\{x_i^{(1)},x_i^{(2)},...,x_i^{(n)}\}\)</span>，即每一个特征向量都有n维，<span class="math inline">\(y_i\in \{c_1,c_2,...,c_k\}\)</span>，即总共有<span class="math inline">\(k\)</span>个标签类别；待预测实例<span class="math inline">\(x\)</span>。</p>
<p>输出：输出实例<span class="math inline">\(x\)</span>所属的标签类别<span class="math inline">\(y\)</span>。</p>
<ul>
<li>计算实例<span class="math inline">\(x\)</span>与所有训练集实例的距离，并从中选取<span class="math inline">\(K\)</span>个最近的实例，这<span class="math inline">\(K\)</span>个点所组成的区域叫做<span class="math inline">\(x\)</span>的邻域。</li>
<li>根据分类决策规则，确定<span class="math inline">\(x\)</span>所属的标签类别<span class="math inline">\(y\)</span>。</li>
</ul>
<p>是不是很简单？🤩从上述过程中，我们可以看到，KNN算法中，最重要的三个要素是：<strong>K值的选择、距离的计算、分类决策规则</strong>。下面就讲一一介绍。</p>
<h2 id="k值的选择">K值的选择</h2>
<p>K值的选择，可以说是整个模型的核心。但是在实际上，并没有具体的公式精确地告诉我们，K值的选择。不过我们可以来分析一下：</p>
<ul>
<li>当K值非常大的时候(譬如K=N)，我们会发现，不管输入的<span class="math inline">\(x\)</span>是什么，结果都不会变，都会偏向于训练集中大多数的那个标签类别，模型过于简单。</li>
<li>当K值非常小的时候(譬如K=1)，那么，只有与输入实例相近的点才会起作用，那么如果恰巧是噪声的话，就会预测错误，所以，我们可以看到，K值太小的话，模型会变得复杂，容易发生过拟合。</li>
</ul>
<p>所以，在实际中，会让K值取一个适中的值，或者采用交叉验证的方式来选取最优的K值。</p>
<h2 id="距离的计算">距离的计算</h2>
<p>在KNN算法中，一般我们会使用欧式距离，但是也有其他的距离，具体如下： <span class="math display">\[
{\text{欧式距离}}\ \ \ \ \  L_2(x_i,x_j)=(\sum_{k=1}^{n}|x_i^{(k)}-x_j^{(k)}|^2)^{\frac 12}\\
{\text{曼哈顿距离}}\ \ \ \ \ \ L_1(x_i,x_j)=(\sum_{k=1}^{n}|x_i^{(k)}-x_j^{(k)}|)\\
{\text{切比雪夫距离}}\ \ \ \ \ \ L_\infty(x_i,x_j)=\mathop{max}\limits_{k=1}^{n}|x_i^{(k)}-x_j^{(k)}|
\]</span> 在KNN中，使用不同的距离度量，所得到的最近邻点是不一样的。</p>
<h2 id="分类决策规则">分类决策规则</h2>
<p>在KNN中，分类决策规则一般都是多数表决。即：<strong>由K个实例中的多数标签类别决定。</strong>使用公式表达如下： <span class="math display">\[
y=argmax_{c_j}\sum_{x_i\in N_k(x)}I(y_i=c_j)
\]</span> 其中，<span class="math inline">\(I\)</span>是指示函数。</p>
<h2 id="kd-tree">kd tree</h2>
<p>其实，介绍完三要素后，KNN算法算是完成了。但是我们来思考一下KNN算法。我们每预测一个实例，都需要计算其与训练集所有实例的距离，并且从中取出K个实例。如果说，数据是高维的，并且训练集非常的大(mnist训练数据集中，有60000个)，那么计算就会变得非常的慢。如果说测试集也非常大的话，那么所花费的时候就会更长。为了解决这个问题，就有人提出了kdtree。<strong>注意：这里的k说的是对k维空间进行划分，与K值不是一个概念！</strong></p>
<p><strong>所谓的kdtree，就是将特征空间划分为多个区域，如果说一些区域离待预测的实例的距离太远，那么就可以放弃掉这些区域，这样就大大减小了比较次数，提高了计算效率。</strong></p>
<p>那我们具体来剖析一下kdtree。它其实是BST的变体。BST，相信只要学过数据结构，应该都非常熟悉。<strong>BST的左子树都比起父节点的值要小，其右子树都比父节点的值要大。</strong>但是在BST中，所有节点都是一维数据，而在，kdtree中，所有节点都是多维数据。下面举个例子来说明kdtree是怎么工作的(《统计学习方法》中其实并没有讲地特别清楚😩)：</p>
<p><img src="/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg"></p>
<p>譬如说有集合<span class="math inline">\(\{(2,3)，(5,4)，(9,6)，(4,7)，(8,1)，(7,2)\}\)</span>。那么kdtree构建过程如下：</p>
<ul>
<li>构建根节点时，此时的切分维度为<span class="math inline">\(x\)</span>，集合在x维从小到大排序为<span class="math inline">\((2,3)，(4,7)，(5,4)，(7,2)，(8,1)，(9,6)\)</span>；它的中值为(7,2)。**注意：2,4,5,7,8,9在数学中的中值为(5 + 7)/2=6，但因该算法的中值需在点集合之内，所以中值计算用的是 $len(points)//2=3, points[3]=(7,2) <span class="math inline">\(）。**所以，\)</span>(2,3)，(4,7)，(5,4)<span class="math inline">\(挂在\)</span>(7,2)<span class="math inline">\(节点的左子树，\)</span>(8,1)，(9,6)<span class="math inline">\(挂在\)</span>(7,2)$节点的右子树。</li>
<li>构建<span class="math inline">\((7,2)\)</span>节点的左子树时，点集合<span class="math inline">\((2,3)，(4,7)[\)</span>]()，(5,4)此时的切分维度为y，中值为<span class="math inline">\((5,4)\)</span>作为分割平面，<span class="math inline">\((2,3)\)</span>挂在其左子树，<span class="math inline">\((4,7)\)</span>挂在其右子树。</li>
<li>构建<span class="math inline">\((7,2)\)</span>节点的右子树时，点集合<span class="math inline">\((8,1)，(9,6)\)</span>此时的切分维度也为y，中值为<span class="math inline">\((9,6)\)</span>作为分割平面，<span class="math inline">\((8,1)\)</span>挂在其左子树。至此kd tree构建完成。使用二维空间画出来的话，如下：</li>
</ul>
<p><img src="/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/1.jpg"></p>
<p>OK，当构建完kdtree之后，那么<strong>如何对其进行搜索呢？</strong></p>
<ul>
<li><p>我们来查找点<span class="math inline">\((2.1,3.1)\)</span>，在<span class="math inline">\((7,2)\)</span>点测试到达<span class="math inline">\((5,4)\)</span>，在<span class="math inline">\((5,4)\)</span>点测试到达<span class="math inline">\((2,3)\)</span>，然后search_path中的结点为&lt;(7,2), (5,4), (2,3)&gt;，从search_path中取出<span class="math inline">\((2,3)\)</span>作为当前最佳结点nearest, dist为<span class="math inline">\(0.141\)</span>；</p></li>
<li><p>然后回溯至<span class="math inline">\((5,4)\)</span>，以<span class="math inline">\((2.1,3.1)\)</span>为圆心，以<span class="math inline">\(dist=0.141\)</span>为半径画一个圆，并不和超平面<span class="math inline">\(y=4\)</span>相交，所以不必跳到结点<span class="math inline">\((5,4)\)</span>的右子空间去搜索，因为右子空间中不可能有更近样本点了。</p></li>
<li><p>于是在回溯至<span class="math inline">\((7,2)\)</span>，同理，以<span class="math inline">\((2.1,3.1)\)</span>为圆心，以<span class="math inline">\(dist=0.141\)</span>为半径画一个圆并不和超平面<span class="math inline">\(x=7\)</span>相交，所以也不用跳到结点<span class="math inline">\((7,2)\)</span>的右子空间去搜索。</p></li>
<li><p>至此，search_path为空，结束整个搜索，返回nearest<span class="math inline">\((2,3)\)</span>作为<span class="math inline">\((2.1,3.1)\)</span>的最近邻点，最近距离为0.141。</p></li>
</ul>
<p><strong>注意：上述是最近邻的过程，得出一个最靠近待预测实例的点，如果是K近邻的话，同样地，我们可以通过这样的方法，来得到K个最近邻的点。</strong>至此，KNN算法的理论部分就讲完啦🎉</p>
<h2 id="knn算法的实现">KNN算法的实现</h2>
<p>把模型实现一遍才算是真正的吃透了这个模型呀。在这里，我采取了两种方式来实现KNN模型：python实现以及调用scikit-learn库来实现。我的github里面可以下载到所有的代码，欢迎访问我的github，也欢迎大家star和fork。附上<strong>GitHub地址: <a href="https://github.com/codewithzichao/Machine_Learning_Code" target="_blank" rel="noopener">《统计学习方法》及常规机器学习模型实现</a></strong>。具体代码如下：</p>
<h3 id="python实现">python实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#Author:codewithzichao</span></span><br><span class="line"><span class="comment">#E-mail:lizichao@pku.edu.cn</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">数据集：Mnist数据集(只使用了1000来训练，只使用了1000来测试。)</span></span><br><span class="line"><span class="string">结果(准确率)：0.738</span></span><br><span class="line"><span class="string">时间：28.6643168926239</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    加载数据</span></span><br><span class="line"><span class="string">    :param fileName: 数据路径</span></span><br><span class="line"><span class="string">    :return: 返回特征向量与标签类别</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    data_list=[]</span><br><span class="line">    label_list=[]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(fileName,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            curline=line.strip().split(<span class="string">","</span>)</span><br><span class="line"></span><br><span class="line">            data_list.append([int(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> curline[<span class="number">1</span>:]])</span><br><span class="line">            label_list.append(int(curline[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">        data_matrix=np.array(data_list)</span><br><span class="line">        label_matrix=np.array(label_list)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data_matrix,label_matrix</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNN</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,train_data,train_label,K)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        构造函数</span></span><br><span class="line"><span class="string">        :param train_data: 训练集的特征向量</span></span><br><span class="line"><span class="string">        :param train_label: 训练集的类别向量</span></span><br><span class="line"><span class="string">        :param K: 指定的K值</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        self.train_data=train_data</span><br><span class="line">        self.train_label=train_label</span><br><span class="line">        self.input_num=self.train_data.shape[<span class="number">0</span>]</span><br><span class="line">        self.feature=self.train_data.shape[<span class="number">1</span>]</span><br><span class="line">        self.K=K</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_distance</span><span class="params">(self,x1,x2)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        计算两个样本之间的距离，使用欧式距离</span></span><br><span class="line"><span class="string">        :param x1: 第一个样本</span></span><br><span class="line"><span class="string">        :param x2: 第二步样本</span></span><br><span class="line"><span class="string">        :return: 样本之间的距离</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="keyword">return</span> np.sqrt(np.sum(np.square(x1-x2)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_K</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        dist_group=np.zeros(self.input_num)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.input_num):</span><br><span class="line">            x1=self.train_data[i]</span><br><span class="line">            dist=self.cal_distance(x,x1)</span><br><span class="line">            dist_group[i]=dist</span><br><span class="line"></span><br><span class="line">        topK=np.argsort(dist_group)[:self.K]<span class="comment">#升序排序</span></span><br><span class="line"></span><br><span class="line">        labeldist=np.zeros(<span class="number">10</span>)<span class="comment">#10个标签，在每一个标签对应的位置上加1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(topK)):</span><br><span class="line">            labeldist[int(self.train_label[topK[i]])]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.argmax(labeldist)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(self,test_data,test_label)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        在测试集上测试</span></span><br><span class="line"><span class="string">        :param test_data: 测试集的特征向量</span></span><br><span class="line"><span class="string">        :param test_label: 测试集的标签向量</span></span><br><span class="line"><span class="string">        :return: 准确率</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        error=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        test_num=test_data.shape[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(test_num):</span><br><span class="line">            print(<span class="string">f"the current sample is <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>,the total samples is<span class="subst">&#123;test_num&#125;</span>."</span>)</span><br><span class="line">            x=test_data[i]</span><br><span class="line">            y=self.get_K(x)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(y!=test_label[i]):</span><br><span class="line">                error+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        accuracy=(test_num-error)/test_num</span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    start=time.time()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"start load data."</span>)</span><br><span class="line">    train_data,train_label=loadData(<span class="string">"../MnistData/mnist_train.csv"</span>)</span><br><span class="line">    test_data,test_label=loadData(<span class="string">"../MnistData/mnist_test.csv"</span>)</span><br><span class="line">    print(<span class="string">"finished load data."</span>)</span><br><span class="line"></span><br><span class="line">    a=KNN(train_data[:<span class="number">1000</span>],train_label[:<span class="number">1000</span>],<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"finished training."</span>)</span><br><span class="line"></span><br><span class="line">    accuracy=a.test(test_data[:<span class="number">1000</span>],test_label[:<span class="number">1000</span>])</span><br><span class="line">    print(<span class="string">f"the accuracy is <span class="subst">&#123;accuracy&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line">    end=time.time()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f"the total time is <span class="subst">&#123;end-start&#125;</span>."</span>)</span><br></pre></td></tr></table></figure>
<h3 id="scikit-learn实现">scikit-learn实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#Author:codewithzichao</span></span><br><span class="line"><span class="comment">#E-mail:lizichao@pku.edu.cn</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">数据集：Mnist数据集(只使用了1000来训练，只使用了1000来测试。)</span></span><br><span class="line"><span class="string">结果(准确率)：0.799</span></span><br><span class="line"><span class="string">时间：16.832828998565674</span></span><br><span class="line"><span class="string">---------------------------</span></span><br><span class="line"><span class="string">果然，自己写的python没有编写kdtree等部分，效果与时间上都比不上sklearn。</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    加载数据</span></span><br><span class="line"><span class="string">    :param fileName: 数据路径</span></span><br><span class="line"><span class="string">    :return: 返回特征向量与标签类别</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    data_list=[]</span><br><span class="line">    label_list=[]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(fileName,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">            curline=line.strip().split(<span class="string">","</span>)</span><br><span class="line"></span><br><span class="line">            data_list.append([int(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> curline[<span class="number">1</span>:]])</span><br><span class="line">            label_list.append(int(curline[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">        data_matrix=np.array(data_list)</span><br><span class="line">        label_matrix=np.array(label_list)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> data_matrix,label_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"start load data."</span>)</span><br><span class="line">    train_data, train_label = loadData(<span class="string">"../MnistData/mnist_train.csv"</span>)</span><br><span class="line">    test_data, test_label = loadData(<span class="string">"../MnistData/mnist_test.csv"</span>)</span><br><span class="line">    print(<span class="string">"finished load data."</span>)</span><br><span class="line"></span><br><span class="line">    knn=KNeighborsClassifier(n_neighbors=<span class="number">10</span>)</span><br><span class="line">    knn.fit(train_data[:<span class="number">1000</span>],train_label[:<span class="number">1000</span>])</span><br><span class="line"></span><br><span class="line">    prediction=knn.predict(test_data[:<span class="number">1000</span>])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        print(<span class="string">f"predict is <span class="subst">&#123;prediction[i]&#125;</span>,the true is <span class="subst">&#123;test_label[i]&#125;</span>."</span>)</span><br><span class="line">    accuracy=knn.score(test_data[:<span class="number">1000</span>],test_label[:<span class="number">1000</span>])</span><br><span class="line">    print(<span class="string">f"the accuracy is <span class="subst">&#123;accuracy&#125;</span>."</span>)</span><br><span class="line"></span><br><span class="line">    end=time.time()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">f"the total time is <span class="subst">&#123;end-start&#125;</span>."</span>)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag"># 统计学习方法</a>
              <a href="/tags/scikit-learn/" rel="tag"># scikit-learn</a>
              <a href="/tags/KNN/" rel="tag"># KNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/02/24/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/" rel="prev" title="统计学习方法|条件随机场模型原理详解与实现">
                  <i class="fa fa-chevron-left"></i> 统计学习方法|条件随机场模型原理详解与实现
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/" rel="next" title="统计学习方法|决策树模型原理详解与实现">
                  统计学习方法|决策树模型原理详解与实现 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zichao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  


















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"live2d-widget-model-hijiki"},"display":{"position":"right","width":225,"height":450},"mobile":{"show":false}});</script></body>
</html>
