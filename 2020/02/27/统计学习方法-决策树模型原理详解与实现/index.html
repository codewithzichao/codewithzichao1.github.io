<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"codewithzichao.github.io","root":"/","scheme":"Muse","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="决策树模型一种基本的分类与回归方法，是shallow learning的Adaboost、XGBoost、Light GBM、catBoost等树模型的基础，对于理解这些模型大有裨益。这篇博客将详细地讲解基本的决策树模型，主要会侧重回归树的讲解，因为这是Adaboost、XGBoost、Light GBM、catBoost等树模型的核心组成部分。并采用python与scikit-learn来对其进">
<meta property="og:type" content="article">
<meta property="og:title" content="统计学习方法|决策树模型原理详解与实现">
<meta property="og:url" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="codewithzichao">
<meta property="og:description" content="决策树模型一种基本的分类与回归方法，是shallow learning的Adaboost、XGBoost、Light GBM、catBoost等树模型的基础，对于理解这些模型大有裨益。这篇博客将详细地讲解基本的决策树模型，主要会侧重回归树的讲解，因为这是Adaboost、XGBoost、Light GBM、catBoost等树模型的核心组成部分。并采用python与scikit-learn来对其进">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/1.jpg">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/2.jpg">
<meta property="og:image" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/3.jpg">
<meta property="article:published_time" content="2020-02-27T02:14:42.000Z">
<meta property="article:modified_time" content="2020-02-28T01:13:09.942Z">
<meta property="article:author" content="zichao">
<meta property="article:tag" content="python">
<meta property="article:tag" content="统计学习方法">
<meta property="article:tag" content="scikit-learn">
<meta property="article:tag" content="CART">
<meta property="article:tag" content="回归树">
<meta property="article:tag" content="decision tree">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg">


<link rel="canonical" href="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>统计学习方法|决策树模型原理详解与实现 | codewithzichao</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">codewithzichao</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Confident，Modest，Patient</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型介绍"><span class="nav-number">1.</span> <span class="nav-text">决策树模型介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#特征选择"><span class="nav-number">1.1.</span> <span class="nav-text">特征选择</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#信息增益"><span class="nav-number">1.1.1.</span> <span class="nav-text">信息增益</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#信息增益比"><span class="nav-number">1.1.2.</span> <span class="nav-text">信息增益比</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树的生成"><span class="nav-number">1.2.</span> <span class="nav-text">决策树的生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树的剪枝"><span class="nav-number">1.3.</span> <span class="nav-text">决策树的剪枝</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cart"><span class="nav-number">2.</span> <span class="nav-text">CART</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型的实现"><span class="nav-number">3.</span> <span class="nav-text">决策树模型的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#python实现"><span class="nav-number">3.1.</span> <span class="nav-text">python实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#scikit-learn实现"><span class="nav-number">3.2.</span> <span class="nav-text">scikit-learn实现</span></a></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zichao</p>
  <div class="site-description" itemprop="description">Just learning</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">80</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">117</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://codewithzichao.github.io/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zichao">
      <meta itemprop="description" content="Just learning">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="codewithzichao">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          统计学习方法|决策树模型原理详解与实现
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-02-27 10:14:42" itemprop="dateCreated datePublished" datetime="2020-02-27T10:14:42+08:00">2020-02-27</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-02-28 09:13:09" itemprop="dateModified" datetime="2020-02-28T09:13:09+08:00">2020-02-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>决策树模型一种基本的分类与回归方法，是shallow learning的Adaboost、XGBoost、Light GBM、catBoost等树模型的基础，对于理解这些模型大有裨益。这篇博客将详细地讲解基本的决策树模型，主要会侧重回归树的讲解，因为这是Adaboost、XGBoost、Light GBM、catBoost等树模型的核心组成部分。并采用python与scikit-learn来对其进行实现。</p>
<a id="more"></a>
<h2 id="决策树模型介绍">决策树模型介绍</h2>
<p>决策树模型是比较简单的模型。它的三个核心问题是：<strong>特征选择、决策树的生成、决策树的剪枝</strong>。</p>
<h3 id="特征选择">特征选择</h3>
<p>所谓的特征选择，我们可以这么想：在没有构建决策树之前，只看训练数据集，是很混乱的，因为我们无法根据训练数据集，直接判断新的实例的类别，也就是说，训练集是没有分类能力的。那么，我们就需要构建一套规则，当我们应用这套规则的时候，我们能够得到实例的类别。那么，问题来了：<strong>我们怎么选择分类的特征，才能使得分类的效果最好呢？</strong>这就是特征选择需要做的事情。常见的应用与特征选择的准则有：<strong>信息增益与信息增益比。</strong></p>
<h4 id="信息增益">信息增益</h4>
<p><strong>信息增益表示在已知特征<span class="math inline">\(A\)</span>的条件下，从而使得数据集的不确定性减少的程度。</strong>看到不确定性，很自然地就会联想到熵！因为熵正是用来度量随机变量不确定性的程度。那么，下面给出熵的定义：</p>
<p>假设离散随机变量<span class="math inline">\(X\)</span>的概率分布是：<span class="math inline">\(P(X=i)=p_i,i=1,2,...,n\)</span>，那么随机变量<span class="math inline">\(X\)</span>的熵如下： <span class="math display">\[
H(p)=-\sum_{i=1}^{n}p_ilog(p_i)
\]</span> 在给定<span class="math inline">\(X\)</span>的情况下，随机变量<span class="math inline">\(Y\)</span>的条件概率分布<span class="math inline">\(P(Y|X)\)</span>的条件熵如下： <span class="math display">\[
H(Y|X)=\sum_{i=1}^{n}p_iP(Y|X=x_i)
\]</span> 当其中的概率是由数据估计(MLE)得到的时候，就称为经验条件熵。</p>
<p>在知道熵的概念之后，那么信息增益的定义如下： <span class="math display">\[
g(D,A)=H(D)-H(D|A)
\]</span> 其中，<span class="math inline">\(D\)</span>表示训练数据集，<span class="math inline">\(A\)</span>表示特征。即：特征A对于训练数据集<span class="math inline">\(D\)</span>的信息增益就等于<span class="math inline">\(D\)</span>的经验熵与给定特征<span class="math inline">\(A\)</span>的情况下<span class="math inline">\(D\)</span>的经验条件熵之差。那么对于决策树模型来说，特征选择的准则是：<strong>选择信息增益大的特征，因为信息增益大的特征具有更强的分类能力。</strong>具体过程如下：</p>
<p><img src="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/0.jpg"></p>
<p><img src="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/1.jpg" style="zoom: 50%;"></p>
<h4 id="信息增益比">信息增益比</h4>
<p>那么有了信息增益，为啥还要有信息增益比呢？原因在于：使用信息增益准则会导致决策树会更加偏向于特征取值数目多的特征。因为，选取特征取值数目多的特征，会让训练集的信息增益增大，也就是整个训练集的不纯度降低。但是，这样以来，会导致构建的决策树模型容易过拟合。因此，就有了信息增益比。 <span class="math display">\[
g_R(D,A)=\frac {g(D,A)}{H_A(D)},\\
H_A(D)=-\sum_{i=1}^{n}\frac {|D_i|}{|D|}log_2\frac {|D_i|}{|D|}
\]</span></p>
<h3 id="决策树的生成">决策树的生成</h3>
<p>决策树的生成算法有3中：ID3、C4.5、CART。在这里，我将讲解ID3、C4.5。CART将单独讲，因为其是后来那些大火的集成模型的核心部分。ID3与C4.5其实差不多，但是它们之间的区别在于特征选择的准则不同：<strong>ID3使用了信息增益，C4.5使用了信息增益比。</strong>在这里，我放上《统计学习方法》中关于C4.5的算法过程。</p>
<p><img src="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/2.jpg" style="zoom:50%;"></p>
<h3 id="决策树的剪枝">决策树的剪枝</h3>
<p>当我们构建好了决策树之后，我们会发现这样构建的决策树很容易发生过拟合。原因在于：<strong>我们在构建决策树的时候，尽可能地去拟合训练数据，从而得到了过于复杂的决策树。</strong>那么一种很自然的想法就是：对决策树进行剪枝，从而让决策树不那么复杂。当然，这样以来，就会使得决策树的准确率下降，所以，我们就需要在模型复杂度与对训练集的预测误差之间做一个tradeoff。我们所用的损失函数如下： <span class="math display">\[
C_{\alpha}(T)=C(T)+\alpha|T|
\]</span> 其中，<span class="math inline">\(T\)</span>表示决策树，<span class="math inline">\(\alpha\)</span>是参数，用来平衡模型复杂度与预测误差之间的关系。<span class="math inline">\(C(T)\)</span>表示模型对训练数据的误差，<span class="math inline">\(|T|\)</span>表示模型的复杂度。当<span class="math inline">\(\alpha\)</span>越大，模型越简单。(我们可以这么记：当<span class="math inline">\(\alpha\)</span>为0的时候，决策树是过拟合的，所以增大<span class="math inline">\(\alpha\)</span>，会让决策树变得简单。)</p>
<h2 id="cart">CART</h2>
<p>CART，全名叫作：分类与回归树。所以，正如名字一样，它既可以用于分类，也可以用于回归问题。在<strong>分类问题</strong>中，使用的特征选择的准则是：<strong>基尼指数(Gini)最小化</strong>；对于<strong>回归问题</strong>，使用的生成方法是：<strong>平方误差最小化</strong>。分类问题我就不介绍了，只介绍一下用于回归问题的回归树。</p>
<p>给定训练数据集<span class="math inline">\(X=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)</span>，那么回归问题就是我们要构造一个函数<span class="math inline">\(f(x)\)</span>，能够使得训练数据集的MSE最小，即： <span class="math display">\[
min\sum_{i=1}^{N}(f(x_i)-y_i)^2
\]</span> 假设，我们将输入空间划分为<span class="math inline">\(R_1,R_2,...,R_M\)</span>，并且在每一个区域有一个输出常数<span class="math inline">\(c_m\)</span>。那么目标函数可以表示为： <span class="math display">\[
min\sum_{i=1}^{N}\sum_{x_i\in R_m}(c_m-y_i)^2
\]</span> 而其中<span class="math inline">\(c_m\)</span>的最优值为就是为该区域的均值，如下： <span class="math display">\[
\hat c_m=ave(y_i|x_i\in R_m)
\]</span> 所以，回归树就可以表示为： <span class="math display">\[
f(x)=\sum_{m=1}^{M}c_mI(x\in R_m)
\]</span> 那么关键是，<strong>怎么对输入空间进行划分呢？</strong>方法：比那里所有的切分变量与切分点，找到使得MSE最小的划分。假设首先随机选择第<span class="math inline">\(j\)</span>个特征做为划分变量，其对应的值为<span class="math inline">\(s\)</span>，那么我们就讲空间划分为两个，如下： <span class="math display">\[
R_1(j,s)=\{x|x^{(j)}&lt;=s\},\\
R_2(j,s)=\{x|x^{(j)}&gt;s\}
\]</span> 接下来，我们需要通过如下函数<span class="math inline">\(m(s)\)</span>，从而找到最优的划分变量与划分值，如下： <span class="math display">\[
\mathop{min}\limits_{j,s}[\mathop{min}\limits_{c_1}\sum_{x_i\in R_1}{(y_i-c_1)^2}+\mathop{min}\limits_{c_2}\sum_{x_i\in R_2}{(y_i-c_2)^2}]
\]</span> 其中，<span class="math inline">\(\hat c_m=ave(y_i|x_i\in R_m),m=1,2\)</span>。那么，遍历所有的变量，找到最小<span class="math inline">\(m(s)\)</span>的<span class="math inline">\(j,s,c_m\)</span>，那么就可以得到最后的回归树了。(在这里附上《统计学习方法》的图)。具体的计算例子，参考：<a href="https://zhuanlan.zhihu.com/p/36108972" target="_blank" rel="noopener">GBDT计算</a>，这里虽然讲解的是提升树，但是由于回归问题的提升树是以回归树做为基本分类器，所以其中也涉及到了回归树的构建过程。</p>
<p><img src="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/3.jpg" style="zoom:50%;"></p>
<p>OK，理论部分就讲完了🎉～</p>
<h2 id="决策树模型的实现">决策树模型的实现</h2>
<p>把模型实现一遍才算是真正的吃透了这个模型呀。在这里，我采取了两种方式来实现决策树模型：python实现以及调用scikit-learn库来实现。我的github里面可以下载到所有的代码，欢迎访问我的github，也欢迎大家star和fork。附上<strong>GitHub地址: <a href="https://github.com/codewithzichao/Machine_Learning_Code" target="_blank" rel="noopener">《统计学习方法》及常规机器学习模型实现</a></strong>。具体代码如下：</p>
<h3 id="python实现">python实现</h3>
<h3 id="scikit-learn实现">scikit-learn实现</h3>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag"># 统计学习方法</a>
              <a href="/tags/scikit-learn/" rel="tag"># scikit-learn</a>
              <a href="/tags/CART/" rel="tag"># CART</a>
              <a href="/tags/%E5%9B%9E%E5%BD%92%E6%A0%91/" rel="tag"># 回归树</a>
              <a href="/tags/decision-tree/" rel="tag"># decision tree</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/02/26/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BD%9C%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/" rel="prev" title="统计学习方法|K近邻算法原理详解与实现">
                  <i class="fa fa-chevron-left"></i> 统计学习方法|K近邻算法原理详解与实现
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/02/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-AdaBoost%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E7%8E%B0/" rel="next" title="统计学习方法|AdaBoost模型原理详解与实现">
                  统计学习方法|AdaBoost模型原理详解与实现 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zichao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  


















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"live2d-widget-model-hijiki"},"display":{"position":"right","width":225,"height":450},"mobile":{"show":false}});</script></body>
</html>
